# LoRAâ€¯DatasetÂ ToolsÂ ğŸ› ï¸

All tools are based on a workflow using https://huggingface.co/deepghs datasets.

Scripts that help you **collect, clean and prepare image datasets** for training
LoRA / DreamBooth / SDXL finetunes.

| Pipeline stage | Script | What it does |
| -------------- | ------ | ------------ |
| 1ï¸âƒ£ Filter & download | `Pull images 2.py` | Query the **Danbooruâ€¯2024** metadata parquet, apply powerful tag/size/score filters, and (optionally) download the resulting images via [`cheesechaser`](https://github.com/deepghs/cheesechaser).Â It also writes perâ€‘image JSON sideâ€‘cars or one master metadata file. :contentReference[oaicite:0]{index=0} |
| 2ï¸âƒ£ Sort by aspect | `sizesorter.py` | Moves *nonâ€‘square* images (or those below a size threshold) into a separate folder for followâ€‘up processing. Uses multithreading for speed. :contentReference[oaicite:1]{index=1} |
| 3ï¸âƒ£ Autoâ€‘crop | `crop.py` | Generates one or many centered **1:1 crops** from large images, with optional controlled overlap and minimumâ€‘size enforcement. :contentReference[oaicite:2]{index=2} |
| 4ï¸âƒ£ Clean orphan files | `cleanup.py` | Removes images that lost their JSON (or JSONs that lost their image) after manual editing. Multithreaded for large folders. :contentReference[oaicite:3]{index=3} |
| 5ï¸âƒ£ Purge unwanted tags | `tag cleaner.py` | Recursively deletes any imageÂ +Â JSON pair that contains an *exact* keyword (caseâ€‘insensitive). :contentReference[oaicite:4]{index=4} |
| (Optional) Schema peek | `import pyarrow.py` | Quick oneâ€‘liner to print the column names of a Danbooru parquet with **PyArrow**. |

---

## QuickÂ start

```bash
# 0.Â Clone repo & enter it
git clone https://github.com/grio43/LORA-tools.git
cd LORA-tools

# 1.Â Create & activate a PythonÂ 3.10+ venv (recommended)
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
